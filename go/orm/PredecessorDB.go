// generated by stacks/gong/go/models/orm_file_per_struct_back_repo.go
package orm

import (
	"database/sql"
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"sort"
	"time"

	"gorm.io/gorm"

	"github.com/tealeg/xlsx/v3"

	"github.com/fullstack-lang/gongplanning/go/db"
	"github.com/fullstack-lang/gongplanning/go/models"
)

// dummy variable to have the import declaration wihthout compile failure (even if no code needing this import is generated)
var dummy_Predecessor_sql sql.NullBool
var dummy_Predecessor_time time.Duration
var dummy_Predecessor_sort sort.Float64Slice

// PredecessorAPI is the input in POST API
//
// for POST, API, one needs the fields of the model as well as the fields
// from associations ("Has One" and "Has Many") that are generated to
// fullfill the ORM requirements for associations
//
// swagger:model predecessorAPI
type PredecessorAPI struct {
	gorm.Model

	models.Predecessor_WOP

	// encoding of pointers
	// for API, it cannot be embedded
	PredecessorPointersEncoding PredecessorPointersEncoding
}

// PredecessorPointersEncoding encodes pointers to Struct and
// reverse pointers of slice of poitners to Struct
type PredecessorPointersEncoding struct {
	// insertion for pointer fields encoding declaration

	// field Task is a pointer to another Struct (optional or 0..1)
	// This field is generated into another field to enable AS ONE association
	TaskID sql.NullInt64
}

// PredecessorDB describes a predecessor in the database
//
// It incorporates the GORM ID, basic fields from the model (because they can be serialized),
// the encoded version of pointers
//
// swagger:model predecessorDB
type PredecessorDB struct {
	gorm.Model

	// insertion for basic fields declaration

	// Declation for basic field predecessorDB.Name
	Name_Data sql.NullString

	// Declation for basic field predecessorDB.DependencyType
	DependencyType_Data sql.NullString

	// encoding of pointers
	// for GORM serialization, it is necessary to embed to Pointer Encoding declaration
	PredecessorPointersEncoding
}

// PredecessorDBs arrays predecessorDBs
// swagger:response predecessorDBsResponse
type PredecessorDBs []PredecessorDB

// PredecessorDBResponse provides response
// swagger:response predecessorDBResponse
type PredecessorDBResponse struct {
	PredecessorDB
}

// PredecessorWOP is a Predecessor without pointers (WOP is an acronym for "Without Pointers")
// it holds the same basic fields but pointers are encoded into uint
type PredecessorWOP struct {
	ID int `xlsx:"0"`

	// insertion for WOP basic fields

	Name string `xlsx:"1"`

	DependencyType models.DependencyType `xlsx:"2"`
	// insertion for WOP pointer fields
}

var Predecessor_Fields = []string{
	// insertion for WOP basic fields
	"ID",
	"Name",
	"DependencyType",
}

type BackRepoPredecessorStruct struct {
	// stores PredecessorDB according to their gorm ID
	Map_PredecessorDBID_PredecessorDB map[uint]*PredecessorDB

	// stores PredecessorDB ID according to Predecessor address
	Map_PredecessorPtr_PredecessorDBID map[*models.Predecessor]uint

	// stores Predecessor according to their gorm ID
	Map_PredecessorDBID_PredecessorPtr map[uint]*models.Predecessor

	db db.DBInterface

	stage *models.StageStruct
}

func (backRepoPredecessor *BackRepoPredecessorStruct) GetStage() (stage *models.StageStruct) {
	stage = backRepoPredecessor.stage
	return
}

func (backRepoPredecessor *BackRepoPredecessorStruct) GetDB() db.DBInterface {
	return backRepoPredecessor.db
}

// GetPredecessorDBFromPredecessorPtr is a handy function to access the back repo instance from the stage instance
func (backRepoPredecessor *BackRepoPredecessorStruct) GetPredecessorDBFromPredecessorPtr(predecessor *models.Predecessor) (predecessorDB *PredecessorDB) {
	id := backRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor]
	predecessorDB = backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[id]
	return
}

// BackRepoPredecessor.CommitPhaseOne commits all staged instances of Predecessor to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoPredecessor *BackRepoPredecessorStruct) CommitPhaseOne(stage *models.StageStruct) (Error error) {

	for predecessor := range stage.Predecessors {
		backRepoPredecessor.CommitPhaseOneInstance(predecessor)
	}

	// parse all backRepo instance and checks wether some instance have been unstaged
	// in this case, remove them from the back repo
	for id, predecessor := range backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr {
		if _, ok := stage.Predecessors[predecessor]; !ok {
			backRepoPredecessor.CommitDeleteInstance(id)
		}
	}

	return
}

// BackRepoPredecessor.CommitDeleteInstance commits deletion of Predecessor to the BackRepo
func (backRepoPredecessor *BackRepoPredecessorStruct) CommitDeleteInstance(id uint) (Error error) {

	predecessor := backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr[id]

	// predecessor is not staged anymore, remove predecessorDB
	predecessorDB := backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[id]
	db, _ := backRepoPredecessor.db.Unscoped()
	_, err := db.Delete(&predecessorDB)
	if err != nil {
		log.Fatal(err)
	}

	// update stores
	delete(backRepoPredecessor.Map_PredecessorPtr_PredecessorDBID, predecessor)
	delete(backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr, id)
	delete(backRepoPredecessor.Map_PredecessorDBID_PredecessorDB, id)

	return
}

// BackRepoPredecessor.CommitPhaseOneInstance commits predecessor staged instances of Predecessor to the BackRepo
// Phase One is the creation of instance in the database if it is not yet done to get the unique ID for each staged instance
func (backRepoPredecessor *BackRepoPredecessorStruct) CommitPhaseOneInstance(predecessor *models.Predecessor) (Error error) {

	// check if the predecessor is not commited yet
	if _, ok := backRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor]; ok {
		return
	}

	// initiate predecessor
	var predecessorDB PredecessorDB
	predecessorDB.CopyBasicFieldsFromPredecessor(predecessor)

	_, err := backRepoPredecessor.db.Create(&predecessorDB)
	if err != nil {
		log.Fatal(err)
	}

	// update stores
	backRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor] = predecessorDB.ID
	backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr[predecessorDB.ID] = predecessor
	backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[predecessorDB.ID] = &predecessorDB

	return
}

// BackRepoPredecessor.CommitPhaseTwo commits all staged instances of Predecessor to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoPredecessor *BackRepoPredecessorStruct) CommitPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	for idx, predecessor := range backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr {
		backRepoPredecessor.CommitPhaseTwoInstance(backRepo, idx, predecessor)
	}

	return
}

// BackRepoPredecessor.CommitPhaseTwoInstance commits {{structname }} of models.Predecessor to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoPredecessor *BackRepoPredecessorStruct) CommitPhaseTwoInstance(backRepo *BackRepoStruct, idx uint, predecessor *models.Predecessor) (Error error) {

	// fetch matching predecessorDB
	if predecessorDB, ok := backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[idx]; ok {

		predecessorDB.CopyBasicFieldsFromPredecessor(predecessor)

		// insertion point for translating pointers encodings into actual pointers
		// commit pointer value predecessor.Task translates to updating the predecessor.TaskID
		predecessorDB.TaskID.Valid = true // allow for a 0 value (nil association)
		if predecessor.Task != nil {
			if TaskId, ok := backRepo.BackRepoTask.Map_TaskPtr_TaskDBID[predecessor.Task]; ok {
				predecessorDB.TaskID.Int64 = int64(TaskId)
				predecessorDB.TaskID.Valid = true
			}
		} else {
			predecessorDB.TaskID.Int64 = 0
			predecessorDB.TaskID.Valid = true
		}

		_, err := backRepoPredecessor.db.Save(&predecessorDB)
		if err != nil {
			log.Fatal(err)
		}

	} else {
		err := errors.New(
			fmt.Sprintf("Unkown Predecessor intance %s", predecessor.Name))
		return err
	}

	return
}

// BackRepoPredecessor.CheckoutPhaseOne Checkouts all BackRepo instances to the Stage
//
// Phase One will result in having instances on the stage aligned with the back repo
// pointers are not initialized yet (this is for phase two)
func (backRepoPredecessor *BackRepoPredecessorStruct) CheckoutPhaseOne() (Error error) {

	predecessorDBArray := make([]PredecessorDB, 0)
	_, err := backRepoPredecessor.db.Find(&predecessorDBArray)
	if err != nil {
		return err
	}

	// list of instances to be removed
	// start from the initial map on the stage and remove instances that have been checked out
	predecessorInstancesToBeRemovedFromTheStage := make(map[*models.Predecessor]any)
	for key, value := range backRepoPredecessor.stage.Predecessors {
		predecessorInstancesToBeRemovedFromTheStage[key] = value
	}

	// copy orm objects to the the map
	for _, predecessorDB := range predecessorDBArray {
		backRepoPredecessor.CheckoutPhaseOneInstance(&predecessorDB)

		// do not remove this instance from the stage, therefore
		// remove instance from the list of instances to be be removed from the stage
		predecessor, ok := backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr[predecessorDB.ID]
		if ok {
			delete(predecessorInstancesToBeRemovedFromTheStage, predecessor)
		}
	}

	// remove from stage and back repo's 3 maps all predecessors that are not in the checkout
	for predecessor := range predecessorInstancesToBeRemovedFromTheStage {
		predecessor.Unstage(backRepoPredecessor.GetStage())

		// remove instance from the back repo 3 maps
		predecessorID := backRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor]
		delete(backRepoPredecessor.Map_PredecessorPtr_PredecessorDBID, predecessor)
		delete(backRepoPredecessor.Map_PredecessorDBID_PredecessorDB, predecessorID)
		delete(backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr, predecessorID)
	}

	return
}

// CheckoutPhaseOneInstance takes a predecessorDB that has been found in the DB, updates the backRepo and stages the
// models version of the predecessorDB
func (backRepoPredecessor *BackRepoPredecessorStruct) CheckoutPhaseOneInstance(predecessorDB *PredecessorDB) (Error error) {

	predecessor, ok := backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr[predecessorDB.ID]
	if !ok {
		predecessor = new(models.Predecessor)

		backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr[predecessorDB.ID] = predecessor
		backRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor] = predecessorDB.ID

		// append model store with the new element
		predecessor.Name = predecessorDB.Name_Data.String
		predecessor.Stage(backRepoPredecessor.GetStage())
	}
	predecessorDB.CopyBasicFieldsToPredecessor(predecessor)

	// in some cases, the instance might have been unstaged. It is necessary to stage it again
	predecessor.Stage(backRepoPredecessor.GetStage())

	// preserve pointer to predecessorDB. Otherwise, pointer will is recycled and the map of pointers
	// Map_PredecessorDBID_PredecessorDB)[predecessorDB hold variable pointers
	predecessorDB_Data := *predecessorDB
	preservedPtrToPredecessor := &predecessorDB_Data
	backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[predecessorDB.ID] = preservedPtrToPredecessor

	return
}

// BackRepoPredecessor.CheckoutPhaseTwo Checkouts all staged instances of Predecessor to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoPredecessor *BackRepoPredecessorStruct) CheckoutPhaseTwo(backRepo *BackRepoStruct) (Error error) {

	// parse all DB instance and update all pointer fields of the translated models instance
	for _, predecessorDB := range backRepoPredecessor.Map_PredecessorDBID_PredecessorDB {
		backRepoPredecessor.CheckoutPhaseTwoInstance(backRepo, predecessorDB)
	}
	return
}

// BackRepoPredecessor.CheckoutPhaseTwoInstance Checkouts staged instances of Predecessor to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoPredecessor *BackRepoPredecessorStruct) CheckoutPhaseTwoInstance(backRepo *BackRepoStruct, predecessorDB *PredecessorDB) (Error error) {

	predecessor := backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr[predecessorDB.ID]

	predecessorDB.DecodePointers(backRepo, predecessor)

	return
}

func (predecessorDB *PredecessorDB) DecodePointers(backRepo *BackRepoStruct, predecessor *models.Predecessor) {

	// insertion point for checkout of pointer encoding
	// Task field
	predecessor.Task = nil
	if predecessorDB.TaskID.Int64 != 0 {
		predecessor.Task = backRepo.BackRepoTask.Map_TaskDBID_TaskPtr[uint(predecessorDB.TaskID.Int64)]
	}
	return
}

// CommitPredecessor allows commit of a single predecessor (if already staged)
func (backRepo *BackRepoStruct) CommitPredecessor(predecessor *models.Predecessor) {
	backRepo.BackRepoPredecessor.CommitPhaseOneInstance(predecessor)
	if id, ok := backRepo.BackRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor]; ok {
		backRepo.BackRepoPredecessor.CommitPhaseTwoInstance(backRepo, id, predecessor)
	}
	backRepo.CommitFromBackNb = backRepo.CommitFromBackNb + 1
}

// CommitPredecessor allows checkout of a single predecessor (if already staged and with a BackRepo id)
func (backRepo *BackRepoStruct) CheckoutPredecessor(predecessor *models.Predecessor) {
	// check if the predecessor is staged
	if _, ok := backRepo.BackRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor]; ok {

		if id, ok := backRepo.BackRepoPredecessor.Map_PredecessorPtr_PredecessorDBID[predecessor]; ok {
			var predecessorDB PredecessorDB
			predecessorDB.ID = id

			if _, err := backRepo.BackRepoPredecessor.db.First(&predecessorDB, id); err != nil {
				log.Fatalln("CheckoutPredecessor : Problem with getting object with id:", id)
			}
			backRepo.BackRepoPredecessor.CheckoutPhaseOneInstance(&predecessorDB)
			backRepo.BackRepoPredecessor.CheckoutPhaseTwoInstance(backRepo, &predecessorDB)
		}
	}
}

// CopyBasicFieldsFromPredecessor
func (predecessorDB *PredecessorDB) CopyBasicFieldsFromPredecessor(predecessor *models.Predecessor) {
	// insertion point for fields commit

	predecessorDB.Name_Data.String = predecessor.Name
	predecessorDB.Name_Data.Valid = true

	predecessorDB.DependencyType_Data.String = predecessor.DependencyType.ToString()
	predecessorDB.DependencyType_Data.Valid = true
}

// CopyBasicFieldsFromPredecessor_WOP
func (predecessorDB *PredecessorDB) CopyBasicFieldsFromPredecessor_WOP(predecessor *models.Predecessor_WOP) {
	// insertion point for fields commit

	predecessorDB.Name_Data.String = predecessor.Name
	predecessorDB.Name_Data.Valid = true

	predecessorDB.DependencyType_Data.String = predecessor.DependencyType.ToString()
	predecessorDB.DependencyType_Data.Valid = true
}

// CopyBasicFieldsFromPredecessorWOP
func (predecessorDB *PredecessorDB) CopyBasicFieldsFromPredecessorWOP(predecessor *PredecessorWOP) {
	// insertion point for fields commit

	predecessorDB.Name_Data.String = predecessor.Name
	predecessorDB.Name_Data.Valid = true

	predecessorDB.DependencyType_Data.String = predecessor.DependencyType.ToString()
	predecessorDB.DependencyType_Data.Valid = true
}

// CopyBasicFieldsToPredecessor
func (predecessorDB *PredecessorDB) CopyBasicFieldsToPredecessor(predecessor *models.Predecessor) {
	// insertion point for checkout of basic fields (back repo to stage)
	predecessor.Name = predecessorDB.Name_Data.String
	predecessor.DependencyType.FromString(predecessorDB.DependencyType_Data.String)
}

// CopyBasicFieldsToPredecessor_WOP
func (predecessorDB *PredecessorDB) CopyBasicFieldsToPredecessor_WOP(predecessor *models.Predecessor_WOP) {
	// insertion point for checkout of basic fields (back repo to stage)
	predecessor.Name = predecessorDB.Name_Data.String
	predecessor.DependencyType.FromString(predecessorDB.DependencyType_Data.String)
}

// CopyBasicFieldsToPredecessorWOP
func (predecessorDB *PredecessorDB) CopyBasicFieldsToPredecessorWOP(predecessor *PredecessorWOP) {
	predecessor.ID = int(predecessorDB.ID)
	// insertion point for checkout of basic fields (back repo to stage)
	predecessor.Name = predecessorDB.Name_Data.String
	predecessor.DependencyType.FromString(predecessorDB.DependencyType_Data.String)
}

// Backup generates a json file from a slice of all PredecessorDB instances in the backrepo
func (backRepoPredecessor *BackRepoPredecessorStruct) Backup(dirPath string) {

	filename := filepath.Join(dirPath, "PredecessorDB.json")

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*PredecessorDB, 0)
	for _, predecessorDB := range backRepoPredecessor.Map_PredecessorDBID_PredecessorDB {
		forBackup = append(forBackup, predecessorDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	file, err := json.MarshalIndent(forBackup, "", " ")

	if err != nil {
		log.Fatal("Cannot json Predecessor ", filename, " ", err.Error())
	}

	err = ioutil.WriteFile(filename, file, 0644)
	if err != nil {
		log.Fatal("Cannot write the json Predecessor file", err.Error())
	}
}

// Backup generates a json file from a slice of all PredecessorDB instances in the backrepo
func (backRepoPredecessor *BackRepoPredecessorStruct) BackupXL(file *xlsx.File) {

	// organize the map into an array with increasing IDs, in order to have repoductible
	// backup file
	forBackup := make([]*PredecessorDB, 0)
	for _, predecessorDB := range backRepoPredecessor.Map_PredecessorDBID_PredecessorDB {
		forBackup = append(forBackup, predecessorDB)
	}

	sort.Slice(forBackup[:], func(i, j int) bool {
		return forBackup[i].ID < forBackup[j].ID
	})

	sh, err := file.AddSheet("Predecessor")
	if err != nil {
		log.Fatal("Cannot add XL file", err.Error())
	}
	_ = sh

	row := sh.AddRow()
	row.WriteSlice(&Predecessor_Fields, -1)
	for _, predecessorDB := range forBackup {

		var predecessorWOP PredecessorWOP
		predecessorDB.CopyBasicFieldsToPredecessorWOP(&predecessorWOP)

		row := sh.AddRow()
		row.WriteStruct(&predecessorWOP, -1)
	}
}

// RestoreXL from the "Predecessor" sheet all PredecessorDB instances
func (backRepoPredecessor *BackRepoPredecessorStruct) RestoreXLPhaseOne(file *xlsx.File) {

	// resets the map
	BackRepoPredecessorid_atBckpTime_newID = make(map[uint]uint)

	sh, ok := file.Sheet["Predecessor"]
	_ = sh
	if !ok {
		log.Fatal(errors.New("sheet not found"))
	}

	// log.Println("Max row is", sh.MaxRow)
	err := sh.ForEachRow(backRepoPredecessor.rowVisitorPredecessor)
	if err != nil {
		log.Fatal("Err=", err)
	}
}

func (backRepoPredecessor *BackRepoPredecessorStruct) rowVisitorPredecessor(row *xlsx.Row) error {

	log.Printf("row line %d\n", row.GetCoordinate())
	log.Println(row)

	// skip first line
	if row.GetCoordinate() > 0 {
		var predecessorWOP PredecessorWOP
		row.ReadStruct(&predecessorWOP)

		// add the unmarshalled struct to the stage
		predecessorDB := new(PredecessorDB)
		predecessorDB.CopyBasicFieldsFromPredecessorWOP(&predecessorWOP)

		predecessorDB_ID_atBackupTime := predecessorDB.ID
		predecessorDB.ID = 0
		_, err := backRepoPredecessor.db.Create(predecessorDB)
		if err != nil {
			log.Fatal(err)
		}
		backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[predecessorDB.ID] = predecessorDB
		BackRepoPredecessorid_atBckpTime_newID[predecessorDB_ID_atBackupTime] = predecessorDB.ID
	}
	return nil
}

// RestorePhaseOne read the file "PredecessorDB.json" in dirPath that stores an array
// of PredecessorDB and stores it in the database
// the map BackRepoPredecessorid_atBckpTime_newID is updated accordingly
func (backRepoPredecessor *BackRepoPredecessorStruct) RestorePhaseOne(dirPath string) {

	// resets the map
	BackRepoPredecessorid_atBckpTime_newID = make(map[uint]uint)

	filename := filepath.Join(dirPath, "PredecessorDB.json")
	jsonFile, err := os.Open(filename)
	// if we os.Open returns an error then handle it
	if err != nil {
		log.Fatal("Cannot restore/open the json Predecessor file", filename, " ", err.Error())
	}

	// read our opened jsonFile as a byte array.
	byteValue, _ := ioutil.ReadAll(jsonFile)

	var forRestore []*PredecessorDB

	err = json.Unmarshal(byteValue, &forRestore)

	// fill up Map_PredecessorDBID_PredecessorDB
	for _, predecessorDB := range forRestore {

		predecessorDB_ID_atBackupTime := predecessorDB.ID
		predecessorDB.ID = 0
		_, err := backRepoPredecessor.db.Create(predecessorDB)
		if err != nil {
			log.Fatal(err)
		}
		backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[predecessorDB.ID] = predecessorDB
		BackRepoPredecessorid_atBckpTime_newID[predecessorDB_ID_atBackupTime] = predecessorDB.ID
	}

	if err != nil {
		log.Fatal("Cannot restore/unmarshall json Predecessor file", err.Error())
	}
}

// RestorePhaseTwo uses all map BackRepo<Predecessor>id_atBckpTime_newID
// to compute new index
func (backRepoPredecessor *BackRepoPredecessorStruct) RestorePhaseTwo() {

	for _, predecessorDB := range backRepoPredecessor.Map_PredecessorDBID_PredecessorDB {

		// next line of code is to avert unused variable compilation error
		_ = predecessorDB

		// insertion point for reindexing pointers encoding
		// reindexing Task field
		if predecessorDB.TaskID.Int64 != 0 {
			predecessorDB.TaskID.Int64 = int64(BackRepoTaskid_atBckpTime_newID[uint(predecessorDB.TaskID.Int64)])
			predecessorDB.TaskID.Valid = true
		}

		// update databse with new index encoding
		db, _ := backRepoPredecessor.db.Model(predecessorDB)
		_, err := db.Updates(*predecessorDB)
		if err != nil {
			log.Fatal(err)
		}
	}

}

// BackRepoPredecessor.ResetReversePointers commits all staged instances of Predecessor to the BackRepo
// Phase Two is the update of instance with the field in the database
func (backRepoPredecessor *BackRepoPredecessorStruct) ResetReversePointers(backRepo *BackRepoStruct) (Error error) {

	for idx, predecessor := range backRepoPredecessor.Map_PredecessorDBID_PredecessorPtr {
		backRepoPredecessor.ResetReversePointersInstance(backRepo, idx, predecessor)
	}

	return
}

func (backRepoPredecessor *BackRepoPredecessorStruct) ResetReversePointersInstance(backRepo *BackRepoStruct, idx uint, predecessor *models.Predecessor) (Error error) {

	// fetch matching predecessorDB
	if predecessorDB, ok := backRepoPredecessor.Map_PredecessorDBID_PredecessorDB[idx]; ok {
		_ = predecessorDB // to avoid unused variable error if there are no reverse to reset

		// insertion point for reverse pointers reset
		// end of insertion point for reverse pointers reset
	}

	return
}

// this field is used during the restauration process.
// it stores the ID at the backup time and is used for renumbering
var BackRepoPredecessorid_atBckpTime_newID map[uint]uint
